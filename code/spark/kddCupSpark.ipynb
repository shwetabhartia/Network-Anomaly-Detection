{"cells":[{"cell_type":"markdown","source":["## Run the cell 1, cell 2 only the first time you execute this notebook"],"metadata":{}},{"cell_type":"code","source":["%sh\nwget -P /tmp \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz\"\ngunzip /tmp/kddcup.data.gz"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["localkddData = \"file:/tmp/kddcup.data\"\ndbutils.fs.mkdirs(\"dbfs:/datasets\")\ndbutils.fs.cp(localkddData, \"dbfs:/datasets/\")\ndisplay(dbutils.fs.ls(\"dbfs:/datasets\"))"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["import numpy\nimport datetime\nfrom pyspark.conf import SparkConf\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.pipeline import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["Creating the schema for the kddcup data"],"metadata":{}},{"cell_type":"code","source":["#Schema for the data\nkddSchema = StructType([StructField('Duration', IntegerType(), True),\n                       StructField('ProtocolType', StringType(), True),\n                       StructField('Service', StringType(), True),\n                       StructField('Flag', StringType(), True),\n                       StructField('SrcBytes',IntegerType(),True),\n                       StructField('DstBytes',IntegerType(),True),\n                       StructField('Land',IntegerType(), True),\n                       StructField('WrongFragment', IntegerType(), True),\n                       StructField('Urgent', IntegerType(), True),\n                       StructField('Hot', IntegerType(), True),\n                       StructField('NumFailedLogins', IntegerType(), True),\n                       StructField('LoggedIn', IntegerType(), True),\n                       StructField('NumCompromised', IntegerType(), True),\n                       StructField('RootShell', IntegerType(), True),\n                       StructField('SuAttempted', IntegerType(), True),\n                       StructField('NumRoot', IntegerType(), True),\n                       StructField('NumFileCreations', IntegerType(), True),\n                       StructField('NumShells', IntegerType(), True),\n                       StructField('NumAccessFiles', IntegerType(), True),\n                       StructField('NumOutboundCmds', IntegerType(), True),\n                       StructField('IsHostLogin', IntegerType(), True),\n                       StructField('IsGuestLogin', IntegerType(), True),\n                       StructField('Count', IntegerType(), True),\n                       StructField('SrvCount', IntegerType(), True),\n                       StructField('SerrorRate', DoubleType(), True),\n                       StructField('SrvSerrorRate', DoubleType(), True),\n                       StructField('RerrorRate', DoubleType(), True),\n                       StructField('SrvRerrorRate', DoubleType(), True),\n                       StructField('SameSrvRate', DoubleType(), True),\n                       StructField('DiffSrvRate', DoubleType(), True),\n                       StructField('SrvDiffHostRate', DoubleType(), True),\n                       StructField('DstHostCount', IntegerType(), True),\n                       StructField('DstHostSrvCount', IntegerType(), True),\n                       StructField('DstHostSameSrvRate', DoubleType(), True),\n                       StructField('DstHostDiffSrvRate', DoubleType(), True),\n                       StructField('DstHostSameSrcPortRate', DoubleType(), True),\n                       StructField('DstHostSrvDiffHostRate', DoubleType(), True),\n                       StructField('DstHostSerrorRate', DoubleType(), True),\n                       StructField('DstHostSrvSerrorRate', DoubleType(), True),\n                       StructField('DstHostRerrorRate', DoubleType(), True),\n                       StructField('DstHostSrvRerrorRate', DoubleType(), True),\n                       StructField('AttackType', StringType(), True)\n                       ])"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Load the kddcup data from Databricks file system into a dataframe by specifying the schema"],"metadata":{}},{"cell_type":"code","source":["#Reading the dataframe from the hdfs file\nkddDF= spark.read.csv('dbfs:/datasets/kddcup.data',header=False, schema=kddSchema)\nkddDF.createOrReplaceTempView(\"kddVIEW\")\n\nkddDF = spark.table(\"kddVIEW\")\ntrainData, testData = kddDF.randomSplit([0.7,0.3], 24)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Transform the set of numerical features on log scale"],"metadata":{}},{"cell_type":"code","source":["#Transforming the features on log scale\ntoTransformFeatures = ['SrcBytes','DstBytes','Duration','Hot','NumFailedLogins','NumCompromised','NumRoot','NumFileCreations','NumAccessFiles','Count','SrvCount','DstHostCount','DstHostSrvCount']\ntrainReplacedDF = trainData.replace(0,1,toTransformFeatures)\ntestReplacedDF = testData.replace(0,1,toTransformFeatures)\nfor feature in toTransformFeatures:\n  trainReplacedDF = trainReplacedDF.withColumn(feature, log(trainReplacedDF[feature]))\n  testReplacedDF = testReplacedDF.withColumn(feature, log(testReplacedDF[feature]))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Index and encode categorical features"],"metadata":{}},{"cell_type":"code","source":["#Indexing and Encoding Categorical features\npipeLineStages = []\ntoIndexColumns = toEncodeColumns = [\"ProtocolType\", \"Service\", \"Flag\", \"AttackType\"]\n\nfor column in toIndexColumns:\n  currentIndexer = column+\"_Indexer\"\n  currentIndexer = StringIndexer(inputCol=column, outputCol=column+\"_index\")\n  pipeLineStages.append(currentIndexer)\n\nfor column in toEncodeColumns:\n  currentEncoder = column+\"_HotEncoder\"\n  currentEncoder = OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_vec\")\n  pipeLineStages.append(currentEncoder)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Creating a list of all the columns that are unimportant for the predictions"],"metadata":{}},{"cell_type":"code","source":["#Creating a list of all the unwanted indexed and categorical features\nindexedAndCategoricalFeatures = ['ProtocolType','Service','Flag','AttackType','AttackType_vec','ProtocolType_index','Service_index','Flag_index']\n\n#Creating a list of all Highly Correlated Columns\nhighlyCorrelatedFeatures = ['SrvRerrorRate', 'DstHostSrvRerrorRate', 'DstHostRerrorRate', 'DstHostSameSrcPortRate', 'DstHostSameSrvRate', 'DstHostSerrorRate', 'DstHostSrvSerrorRate', 'SrvSerrorRate', 'SameSrvRate']\n\n#Creating a list containing the target feature\ntarget_column = ['AttackType_index']\n\n#Creating a list of all unimportant features by getting the list of unwanted features ran by the python proram by my team members\nunimportantFeatures = ['Urgent','NumFailedLogins','NumCompromised','SuAttempted','NumAccessFiles','NumOutboundCmds','IsHostLogin','SrvSerrorRate','SrvRerrorRate','SameSrvRate','DstHostSameSrvRate','DstHostSameSrcPortRate','DstHostSerrorRate','DstHostSrvSerrorRate','DstHostRerrorRate','DstHostSrvRerrorRate']\n\nunwanted_columns = indexedAndCategoricalFeatures + highlyCorrelatedFeatures + target_column + unimportantFeatures"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Creating a Vector of all the features using Vector Assembler"],"metadata":{}},{"cell_type":"code","source":["#Creating an assembler of all the features\nfeature_assembler = VectorAssembler(inputCols = [column for column in testReplacedDF.columns if column not in unwanted_columns], outputCol=\"features\")"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Declare the Decison Tree classifier, Random Forest classifier and KMeans model"],"metadata":{}},{"cell_type":"code","source":["#Declaring a decision tree classifier\ndecisionTree = DecisionTreeClassifier(labelCol='AttackType_index', featuresCol='features')\n#Declaring a random forest classifier\nrandomForest = RandomForestClassifier(labelCol='AttackType_index', featuresCol='features', numTrees=5)\n#Creating a kmeans model\nkMeans = KMeans().setK(30).setSeed(2)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["Create pipeline stages for all the prediction models"],"metadata":{}},{"cell_type":"code","source":["pipeLineStages.append(feature_assembler)\n\ndecisionTreePipeLineStages = list(pipeLineStages)\nrandomForestPipeLineStages = list(pipeLineStages)\nkMeansPipeLineStages = list(pipeLineStages)\n\ndecisionTreePipeLineStages.append(decisionTree)\nrandomForestPipeLineStages.append(randomForest)\nkMeansPipeLineStages.append(kMeans)\n\ndecisionTreePipeLine = Pipeline(stages = decisionTreePipeLineStages)\nrandomForestPipeLine = Pipeline(stages = randomForestPipeLineStages)\nkMeansPipeLine = Pipeline(stages = kMeansPipeLineStages)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["Create an evaluator, with accuracy as a Measure"],"metadata":{}},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(\n    labelCol=\"AttackType_index\", predictionCol=\"prediction\", metricName=\"accuracy\")"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["Run the Decision Tree model"],"metadata":{}},{"cell_type":"code","source":["\n#Creating a model by fitting the traindata with the pipeline\ndecisionTreeModel = decisionTreePipeLine.fit(trainReplacedDF)\n#Making predictions by transforming the testdata\ndecisionTreePredictions = decisionTreeModel.transform(testReplacedDF)\n\ndecisionTreeAccuracy = evaluator.evaluate(decisionTreePredictions)\nprint  \"Decision Tree Accuracy\", decisionTreeAccuracy\nprint \"Decision Tree Error\", 1.0 - decisionTreeAccuracy"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["Run the Random Forest model"],"metadata":{}},{"cell_type":"code","source":["#Creating a model by fitting the traindata with the pipeline\nrandomForestModel = randomForestPipeLine.fit(trainReplacedDF)\n#Making predictions by transforming the testdata\nrandomForestTreePredictions = randomForestModel.transform(testReplacedDF)\n\nrandomForestAccuracy = evaluator.evaluate(randomForestTreePredictions)\nprint  \"Random Forest Accuracy\", randomForestAccuracy\nprint \"Random Forest Error\", 1.0 - randomForestAccuracy"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["Run the kMeans model"],"metadata":{}},{"cell_type":"code","source":["#Creating a model by fitting the traindata with the pipeline\nkMeansModel = kMeansPipeLine.fit(trainReplacedDF)\n#Making predictions by transforming the testdata\nkMeansPredictions = kMeansModel.transform(testReplacedDF)\n\nkMeansPredictions.head()"],"metadata":{},"outputs":[],"execution_count":28}],"metadata":{"name":"kddCupSpark","notebookId":1515819512284237},"nbformat":4,"nbformat_minor":0}
